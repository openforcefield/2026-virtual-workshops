{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Fitting Workshop"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "## Preparing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from qcportal import PortalClient\n",
    "\n",
    "# Connect to the QCArchive portal\n",
    "client = PortalClient(\"https://api.qcarchive.molssi.org\")\n",
    "\n",
    "# Get all dataset names using the newer API\n",
    "datasets = client.list_datasets()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "[\n",
    "    (dataset[\"dataset_name\"], dataset[\"dataset_type\"])\n",
    "    for dataset in datasets\n",
    "    if \"openff\" in dataset[\"dataset_name\"].lower()\n",
    "    and \"lipid\" in dataset[\"dataset_name\"].lower()\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openff.qcsubmit.results import OptimizationResultCollection\n",
    "from qcportal import PortalClient\n",
    "from qcportal.client import SinglepointDriver\n",
    "\n",
    "client = PortalClient(\"https://api.qcarchive.molssi.org\")  # TODO: Caching?\n",
    "\n",
    "results = OptimizationResultCollection.from_server(\n",
    "    client=client,\n",
    "    datasets=[\"OpenFF Protein PDB 4-mers v4.0\"],\n",
    "    spec_name=\"default\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from qcportal.client import SinglepointDriver\n",
    "\n",
    "records, molecules = zip(\n",
    "    *results.to_basic_result_collection(\n",
    "        [*SinglepointDriver],\n",
    "    ).to_records(\n",
    "        include=[\n",
    "            \"molecule\",\n",
    "            \"identifiers\",\n",
    "            \"properties\",\n",
    "        ]\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import descent.targets.energy\n",
    "import numpy\n",
    "import torch\n",
    "import tqdm\n",
    "from openff.units import Quantity, unit\n",
    "\n",
    "data = {}\n",
    "for record in tqdm.tqdm(records):\n",
    "    smiles = (\n",
    "        record.molecule.identifiers.canonical_isomeric_explicit_hydrogen_mapped_smiles\n",
    "    )\n",
    "\n",
    "    geometry = Quantity(record.molecule.geometry, \"bohr\")\n",
    "    return_energy = (\n",
    "        Quantity(\n",
    "            record.properties[\"return_energy\"],\n",
    "            \"hartree\",\n",
    "        )\n",
    "        * unit.avogadro_constant\n",
    "    )\n",
    "    gradient = (\n",
    "        Quantity(\n",
    "            numpy.array(record.properties[\"scf total gradient\"]).reshape((-1, 3)),\n",
    "            \"hartree/bohr\",\n",
    "        )\n",
    "        * unit.avogadro_constant\n",
    "    )\n",
    "\n",
    "    entry = data.setdefault(\n",
    "        smiles,\n",
    "        descent.targets.energy.Entry(\n",
    "            smiles=smiles,\n",
    "            coords=[],\n",
    "            energy=[],\n",
    "            forces=[],\n",
    "        ),\n",
    "    )\n",
    "\n",
    "    entry[\"coords\"].append(geometry.m_as(\"angstrom\"))\n",
    "    entry[\"energy\"].append(return_energy.m_as(\"kcal/mol\"))\n",
    "    entry[\"forces\"].append(-gradient.m_as(\"kcal/mol/angstrom\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openff.toolkit import Molecule\n",
    "\n",
    "for entry in data.values():\n",
    "    n_confs = len(entry[\"energy\"])\n",
    "    n_atoms = Molecule.from_mapped_smiles(entry[\"smiles\"]).n_atoms\n",
    "    entry[\"coords\"] = numpy.asarray(entry[\"coords\"]).reshape(n_confs, n_atoms, 3)\n",
    "    entry[\"forces\"] = numpy.asarray(entry[\"coords\"]).reshape(n_confs, n_atoms, 3)\n",
    "\n",
    "ds = descent.targets.energy.create_dataset(data.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ??filtering??\n",
    "# ??Check coverage??"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9",
   "metadata": {},
   "source": [
    "## Parametrization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openff.toolkit import ForceField, Molecule\n",
    "\n",
    "initial_ff = ForceField(\"openff_unconstrained-2.3.0.offxml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Parallelize?\n",
    "\n",
    "interchanges = [\n",
    "    initial_ff.create_interchange(Molecule.from_mapped_smiles(smiles).to_topology())\n",
    "    for smiles in tqdm.tqdm(ds[\"smiles\"])\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "import smee.converters\n",
    "\n",
    "device = \"cpu\"\n",
    "\n",
    "tensor_ff, tensor_tops = smee.converters.convert_interchange(interchanges)\n",
    "\n",
    "assert len(tensor_tops) == len(interchanges) == len(ds)\n",
    "\n",
    "tensor_tops_by_smiles = {\n",
    "    smiles: ttop.to(device) for smiles, ttop in zip(ds[\"smiles\"], tensor_tops)\n",
    "}\n",
    "tensor_ff = tensor_ff.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13",
   "metadata": {},
   "source": [
    "## Fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "import descent.train\n",
    "\n",
    "parameters = {\n",
    "    \"Bonds\": descent.train.ParameterConfig(\n",
    "        cols=[\"k\", \"length\"],\n",
    "        scales={\"k\": 1.0e-2, \"length\": 1.0},\n",
    "        limits={\"k\": [0.0, None], \"length\": [0.0, None]},\n",
    "    ),\n",
    "    \"Angles\": descent.train.ParameterConfig(\n",
    "        cols=[\"k\", \"angle\"],\n",
    "        scales={\"k\": 1.0e-2, \"angle\": 1.0e-2},\n",
    "        limits={\"k\": [0.0, None], \"angle\": [0.0, 3.141592653589793]},\n",
    "    ),\n",
    "    \"ProperTorsions\": descent.train.ParameterConfig(\n",
    "        cols=[\"k\"],\n",
    "        scales={\"k\": 1.0e1},\n",
    "        limits={\"k\": [0.0, None]},\n",
    "    ),\n",
    "}\n",
    "attributes: dict[str, descent.train.AttributeConfig] = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainable = descent.train.Trainable(\n",
    "    force_field=tensor_ff, parameters=parameters, attributes=attributes\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorboardX\n",
    "import torch\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "energy_weight = 1.0\n",
    "force_weight = 1.0\n",
    "n_epochs = 10\n",
    "learning_rate = 1.0 / 15000\n",
    "batch_size = len(ds)\n",
    "directory = \"tensorboard_logs\"\n",
    "train_data = ds\n",
    "\n",
    "train_dataloader = torch.utils.data.DataLoader(\n",
    "    train_data,\n",
    "    batch_size=batch_size,\n",
    "    collate_fn=lambda samples: samples,\n",
    "    pin_memory=True,\n",
    ")\n",
    "trainable_parameters = trainable.to_values().to(device)\n",
    "\n",
    "print(\"Start training...\")\n",
    "with tensorboardX.SummaryWriter(str(directory)) as writer:\n",
    "    optimizer = torch.optim.Adam(\n",
    "        [trainable_parameters],\n",
    "        lr=learning_rate,\n",
    "        amsgrad=True,\n",
    "    )\n",
    "\n",
    "    epoch_tqdm = tqdm(range(n_epochs), desc=\"epochs\", dynamic_ncols=True)\n",
    "    for i in epoch_tqdm:\n",
    "        ff = trainable.to_force_field(trainable_parameters)\n",
    "        epoch_loss = torch.zeros(size=(1,), device=device)\n",
    "        energy_loss = torch.zeros(size=(1,), device=device)\n",
    "        force_loss = torch.zeros(size=(1,), device=device)\n",
    "        grad = None\n",
    "\n",
    "        batch_tqdm = tqdm(\n",
    "            leave=False,\n",
    "            desc=\"computing loss\",\n",
    "            total=len(train_data),\n",
    "            unit=\"tops\",\n",
    "            dynamic_ncols=True,\n",
    "        )\n",
    "        for cpu_batch in train_dataloader:\n",
    "            # Copy the batch to device\n",
    "            batch = [\n",
    "                {k: v if k == \"smiles\" else v.to(device) for k, v in sample.items()}\n",
    "                for sample in cpu_batch\n",
    "            ]\n",
    "            true_batch_size = len(batch)\n",
    "            # Compute forces and energies\n",
    "            e_ref, e_pred, f_ref, f_pred = descent.targets.energy.predict(\n",
    "                batch,  # type: ignore\n",
    "                ff,\n",
    "                tensor_tops_by_smiles,\n",
    "                \"mean\",\n",
    "            )\n",
    "            # Compute L2 loss\n",
    "            batch_loss_energy = ((e_pred - e_ref) ** 2).sum() / true_batch_size\n",
    "            batch_loss_force = ((f_pred - f_ref) ** 2).sum() / true_batch_size\n",
    "\n",
    "            # Equal sum of L2 loss on energies and forces\n",
    "            batch_loss = batch_loss_energy + batch_loss_force\n",
    "\n",
    "            # Compute the gradient of batch_loss wrt trainable_parameters\n",
    "            (batch_grad,) = torch.autograd.grad(\n",
    "                batch_loss,\n",
    "                trainable_parameters,\n",
    "                create_graph=True,\n",
    "            )\n",
    "            # Add the batch gradient to the cumulative epoch gradient\n",
    "            batch_grad = batch_grad.detach()\n",
    "            if grad is None:\n",
    "                grad = batch_grad\n",
    "            else:\n",
    "                grad += batch_grad\n",
    "\n",
    "            # keep cumulative epoch losses to report MSE at the end\n",
    "            epoch_loss += batch_loss.detach()\n",
    "            energy_loss += batch_loss_energy.detach()\n",
    "            force_loss += batch_loss_force.detach()\n",
    "\n",
    "            # Update the progress bar\n",
    "            batch_tqdm.update(true_batch_size)\n",
    "        batch_tqdm.close()\n",
    "\n",
    "        # Write results to logs\n",
    "        epoch_tqdm.set_description(\n",
    "            f\"loss: {epoch_loss.detach().item()}, epochs\",\n",
    "        )\n",
    "\n",
    "        writer.add_scalar(\"loss\", epoch_loss.detach().item(), i)\n",
    "        writer.add_scalar(\"loss_energy\", energy_loss.detach().item(), i)\n",
    "        writer.add_scalar(\"loss_forces\", force_loss.detach().item(), i)\n",
    "\n",
    "        writer.add_scalar(\"rmse_energy\", energy_loss.detach().sqrt().item(), i)\n",
    "        writer.add_scalar(\"rmse_forces\", force_loss.detach().sqrt().item(), i)\n",
    "        writer.flush()\n",
    "\n",
    "        # Perform the optimization step\n",
    "        trainable_parameters.grad = grad\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir $directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimized_tensor_ff = trainable.to_force_field(trainable_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections.abc import Collection\n",
    "\n",
    "from openff.toolkit.typing.engines.smirnoff.parameters import ParameterHandler\n",
    "\n",
    "HANDLERS_WITHOUT_XML_PARAMETERS = {\n",
    "    \"NAGLChargesHandler\",\n",
    "    \"ToolkitAM1BCCHandler\",\n",
    "}\n",
    "\n",
    "\n",
    "def update_parameters(\n",
    "    handler: ParameterHandler,\n",
    "    potential: smee.TensorPotential,\n",
    "    config: descent.train.ParameterConfig | None,\n",
    "):\n",
    "\n",
    "    for key, values in zip(\n",
    "        potential.parameter_keys,\n",
    "        potential.parameters,\n",
    "        strict=True,\n",
    "    ):\n",
    "        if key.associated_handler in HANDLERS_WITHOUT_XML_PARAMETERS:\n",
    "            continue\n",
    "        parameter = handler[key.id]\n",
    "        for name, unit, value in zip(\n",
    "            potential.parameter_cols,\n",
    "            potential.parameter_units,\n",
    "            values,\n",
    "            strict=True,\n",
    "        ):\n",
    "            if config is not None and name not in config.cols:\n",
    "                continue\n",
    "            name = name if key.mult is None else f\"{name}{key.mult+1}\"\n",
    "            try:\n",
    "                setattr(parameter, name, value * unit)\n",
    "            except Exception:\n",
    "                print(f\"    COULD NOT UPDATE {key.id=} {name=} {unit=} {value=} {key.mult=}\")\n",
    "\n",
    "\n",
    "def update_attributes(\n",
    "    handler: ParameterHandler,\n",
    "    potential: smee.TensorPotential,\n",
    "    config: descent.train.AttributeConfig | None,\n",
    "):\n",
    "    for name, value, unit in zip(\n",
    "        [] if potential.attribute_cols is None else potential.attribute_cols,\n",
    "        [] if potential.attributes is None else potential.attributes,\n",
    "        [] if potential.attribute_units is None else potential.attribute_units,\n",
    "        strict=True,\n",
    "    ):\n",
    "        if config is not None and name not in config.cols:\n",
    "            continue\n",
    "        setattr(handler, name, value * unit)\n",
    "\n",
    "\n",
    "def write_smirnoff(\n",
    "    initial_ff: ForceField,\n",
    "    optimized_tensor_ff: smee.TensorForceField,\n",
    "    parameters: None | dict[str, descent.train.ParameterConfig] = None,\n",
    "    attributes: None | dict[str, descent.train.AttributeConfig] = None,\n",
    "):\n",
    "\n",
    "    optimized_smirnoff_ff = ForceField(initial_ff.to_string())\n",
    "    for potential in optimized_tensor_ff.potentials:\n",
    "        print(potential.type)\n",
    "        handler = optimized_smirnoff_ff[potential.type]\n",
    "        if parameters is None or potential.type in parameters:\n",
    "            print(\"  updating parameters\")\n",
    "            update_parameters(\n",
    "                handler,\n",
    "                potential,\n",
    "                None if parameters is None else parameters[potential.type],\n",
    "            )\n",
    "        if attributes is None or potential.type in attributes:\n",
    "            print(\"  updating attributes\")\n",
    "            update_attributes(\n",
    "                handler,\n",
    "                potential,\n",
    "                None if attributes is None else attributes[potential.type],\n",
    "            )\n",
    "    return optimized_smirnoff_ff\n",
    "\n",
    "\n",
    "optimized_smirnoff_ff = write_smirnoff(\n",
    "    initial_ff,\n",
    "    optimized_tensor_ff,\n",
    "    parameters,\n",
    "    attributes,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "for a, b in zip(optimized_smirnoff_ff.to_string().splitlines(), initial_ff.to_string().splitlines()):\n",
    "    if a != b:\n",
    "        print(f\"INI: {b}\", \"\\n\",f\"OPT: {a}\", sep=\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21",
   "metadata": {},
   "source": [
    "## Benchmarks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22",
   "metadata": {},
   "source": [
    "- Visual inspection of structures\n",
    "- YAMMBS? Not designed to be stable, user-facing software (present as \"our internal benchmark software\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
